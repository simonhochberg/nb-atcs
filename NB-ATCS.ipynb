{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, requests, time, csv, datetime, re, os\n",
    "pd.set_option(\"max_rows\", 100)\n",
    "\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to keep lists of predictions, train numbers the same length\n",
    "# useful for adding these lists to DataFrames\n",
    "\n",
    "def toReadableTime(ts):\n",
    "    return datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S').split()[1]\n",
    "def toReadableDateTime(ts):\n",
    "    return datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "def dayIncrement(readYear, readMonth, readDay):\n",
    "    # 30-day months\n",
    "    if readMonth in [\"04\",\"06\",\"09\",\"11\"]:\n",
    "        if readDay == \"30\":\n",
    "            nextDate = readYear + \"-\" + str(int(readMonth) + 1).zfill(2) + \"-01\"\n",
    "        elif int(readDay) > 30:\n",
    "            print(\"INVALID DATE\")\n",
    "            nextDate = \"INVALID DATE\"\n",
    "        else:\n",
    "            nextDate = readYear + \"-\" + readMonth + \"-\" + str(int(readDay) + 1).zfill(2)\n",
    "    # 31-day months\n",
    "    elif readMonth in [\"01\",\"03\",\"05\",\"07\",\"08\",\"10\"]:\n",
    "        if readDay == \"31\":\n",
    "            nextDate = readYear + \"-\" + str(int(readMonth) + 1).zfill(2) + \"-01\"\n",
    "        elif int(readDay) > 31:\n",
    "            print(\"INVALID DATE\")\n",
    "            nextDate = \"INVALID DATE\"\n",
    "        else:\n",
    "            nextDate = readYear + \"-\" + readMonth + \"-\" + str(int(readDay) + 1).zfill(2)\n",
    "    # December\n",
    "    elif readMonth == \"12\":\n",
    "        if readDay == \"31\":\n",
    "            nextDate = str(int(readYear) + 1) + \"-\" + \"01-01\"\n",
    "        elif int(readDay) > 31:\n",
    "            print(\"INVALID DATE\")\n",
    "            nextDate = \"INVALID DATE\"\n",
    "        else:\n",
    "            nextDate = readYear + \"-\" + readMonth + \"-\" + str(int(readDay) + 1).zfill(2)\n",
    "    # February\n",
    "    elif readMonth == \"02\":\n",
    "        if int(readYear) % 4 != 0:\n",
    "            if readDay == \"28\":\n",
    "                nextDate = readYear + \"-\" + str(int(readMonth) + 1).zfill(2) + \"-01\"\n",
    "            elif int(readDay) > 31:\n",
    "                print(\"INVALID DATE\")\n",
    "                nextDate = \"INVALID DATE\"\n",
    "            else:\n",
    "                nextDate = readYear + \"-\" + readMonth + \"-\" + str(int(readDay) + 1).zfill(2)\n",
    "        else:\n",
    "            if readDay == \"29\":\n",
    "                nextDate = readYear + \"-\" + str(int(readMonth) + 1).zfill(2) + \"-01\"\n",
    "            elif int(readDay) > 31:\n",
    "                print(\"INVALID DATE\")\n",
    "                nextDate = \"INVALID DATE\"\n",
    "            else:\n",
    "                nextDate = readYear + \"-\" + readMonth + \"-\" + str(int(readDay) + 1).zfill(2)\n",
    "    else:\n",
    "        pass\n",
    "    return nextDate\n",
    "\n",
    "def consist_to_four_digit(consist):\n",
    "    if pd.isnull(consist) == False and len(str(consist))>0:\n",
    "        if type(consist) == str:\n",
    "            consist = int(consist)\n",
    "            if consist >= 1 and consist <= 400:\n",
    "                fourdigitconsist = consist + 1199\n",
    "            elif consist >= 501 and consist <= 999:\n",
    "                fourdigitconsist = consist + 1499\n",
    "            else:\n",
    "                fourdigitconsist = int(consist)\n",
    "\n",
    "        else:\n",
    "            consist = int(consist)\n",
    "            if consist >= 1 and consist <= 400:\n",
    "                fourdigitconsist = consist + 1199\n",
    "            elif consist >= 501 and consist <= 999:\n",
    "                fourdigitconsist = consist + 1499\n",
    "            else:\n",
    "                fourdigitconsist = int(consist)\n",
    "    else:\n",
    "        fourdigitconsist = np.NaN\n",
    "    return fourdigitconsist\n",
    "\n",
    "def loadSMC(day2read):\n",
    "    # getfile = \"http://nbsnap/atcslogs/SmcSls/%sSLS.smc\" % str(datetime.datetime.today()).split()[0].replace(\"-\",\"\")[2:]\n",
    "    # day2read should be in the format YYYY-MM-DD\n",
    "    \n",
    "    readYear = day2read.split(\"-\")[0]\n",
    "    readMonth= day2read.split(\"-\")[1]\n",
    "    readDay= day2read.split(\"-\")[2]\n",
    "    \n",
    "    #getfile = \"http://nbsnap/atcslogs/SmcSls/{}SLS.smc\".format((readYear[2:]+readMonth+readDay))\n",
    "    getfile = \"{}SLS.smc\".format((readYear[2:]+readMonth+readDay))\n",
    "    \n",
    "    readMsg = \"Running for {}-{}-{}\".format(readYear, readMonth, readDay)\n",
    "    print(readMsg)\n",
    "    s = requests.get(getfile)\n",
    "    print(s)\n",
    "    \n",
    "    smc = s.text\n",
    "    smcrecords = smc.replace(\"\\n\",\"\").split(\"\\r\")\n",
    "    \n",
    "    # remove records we don't want, so future operations are faster\n",
    "    poplist = []\n",
    "    couples = []\n",
    "\n",
    "    print(len(smcrecords), \"initial records\")\n",
    "\n",
    "    for i in range(len(smcrecords)):\n",
    "        rec = smcrecords[i].replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "        if \"Arrived\" in rec and \"Destination\" in rec and \"Platform\" in rec:\n",
    "            pass\n",
    "        elif \"Vehicle\" in rec and \"IDs\" in rec:\n",
    "            couples.append(smcrecords[i])\n",
    "            poplist.append(i)\n",
    "        else:    \n",
    "            poplist.append(i)\n",
    "\n",
    "    for item in reversed(poplist):\n",
    "        smcrecords.pop(item)\n",
    "\n",
    "    print(len(smcrecords), \"arrival records\")\n",
    "    \n",
    "    smcrecords = smc.replace(\"\\n\",\"\").split(\"\\r\")\n",
    "    \n",
    "    coupleDict = {}\n",
    "\n",
    "    for couple in couples:\n",
    "\n",
    "        info = couple.replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "        veh1 = consist_to_four_digit(info[6])\n",
    "        veh2 = consist_to_four_digit(info[7])\n",
    "\n",
    "        coupleDict[veh1] = veh2\n",
    "        \n",
    "    # remove records we don't want, so future operations are faster\n",
    "    poplist = []\n",
    "    couples = []\n",
    "\n",
    "    for i in range(len(smcrecords)):\n",
    "        rec = smcrecords[i].replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "        if \"Arrived\" in rec and \"Destination\" in rec and \"Platform\" in rec:\n",
    "            pass\n",
    "        elif \"Vehicle\" in rec and \"IDs\" in rec:\n",
    "            couples.append(smcrecords[i])\n",
    "            poplist.append(i)\n",
    "        else:    \n",
    "            poplist.append(i)\n",
    "\n",
    "    for item in reversed(poplist):\n",
    "        smcrecords.pop(item)\n",
    "        \n",
    "    dfs = []\n",
    "\n",
    "    for record in smcrecords:\n",
    "        rec = [x.replace(\"{\",\"\").replace(\"}\",\"\") for x in record.split(\" \",2)]\n",
    "        dfs.append(pd.DataFrame([rec], columns=[\"TIME\", \"SRS_ID\", \"MSG\"]))\n",
    "\n",
    "    smcdf = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    smcdf[\"CONSIST\"] = [re.sub(\"\\D\", \"\", x.lower().split()[x.lower().split().index('consist')+1]) if \"consist\" in x.lower().split() else '' for x in smcdf['MSG']]\n",
    "\n",
    "    smcdf[\"FOUR_DIGIT_CONSIST\"] = [consist_to_four_digit(x) for x in smcdf['CONSIST']]\n",
    "    smcdf[\"PLATFORM\"] = [x.split()[x.split().index(\"Platform\")+1] for x in smcdf[\"MSG\"]]\n",
    "    \n",
    "    smcdf[\"H\"] = [int(x.split(\":\")[0]) for x in smcdf[\"TIME\"]]\n",
    "    dayChangeIdx = smcdf[smcdf[\"H\"].diff() < 0].index[0]\n",
    "    smcdf.drop(\"H\", axis=1, inplace=True)\n",
    "    \n",
    "    smcdf[\"DAY\"] = np.NaN\n",
    "    smcdf.loc[:(dayChangeIdx-1), \"DAY\"] = day2read\n",
    "    smcdf.loc[dayChangeIdx:, \"DAY\"] = dayIncrement(readYear=readYear, readMonth=readMonth, readDay=readDay)\n",
    "    \n",
    "    smcdf[\"DATETIME\"] = smcdf[\"DAY\"] + \" \" + smcdf[\"TIME\"]\n",
    "    \n",
    "    \n",
    "    #smcdf[\"DATETIME\"] = [pd.to_datetime(\"2019-01-16 \" +x) for x in smcdf[\"TIME\"]]\n",
    "    smcdf[\"UNIX\"] = [(time.mktime(time.strptime(str(x).split(\".\")[0], \"%Y-%m-%d %H:%M:%S\"))) for x in smcdf[\"DATETIME\"]]\n",
    "    \n",
    "    return smcdf, coupleDict\n",
    "\n",
    "def generateUniqueId(uid_no):\n",
    "    return str(datetime.datetime.today()).split()[0] + \"--\" + str(uid_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "\n",
    "0. Initialization\n",
    "1. Load NextBus data\n",
    "2. Load ATCS arrival data\n",
    "3. Load ATCS signs data\n",
    "4. Match NB 2 ATCS\n",
    "5. Match ATCS 2 NB\n",
    "6. Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load NextBus Data\n",
    "\n",
    "This steps loads all data collected from NextBus API into memory as a Pandas DataFrame. The data is then filtered to only contrain observations where the next arriving vehicle is predicted to arrive within ten minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"NB-VNR-2019-01-16.csv\"\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "sample = data.query(\"Seconds < 600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 unique vehicles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mapsense-simon/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/mapsense-simon/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 unique arrival IDs\n",
      "CPU times: user 19 s, sys: 102 ms, total: 19.1 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vehicles = list(data[\"Vehicle\"].unique())\n",
    "\n",
    "print(len(vehicles), \"unique vehicles.\")\n",
    "\n",
    "arrivals = pd.DataFrame(columns=[\"Timestamp\", \"Line\", \"Vehicle\", \"Seconds\", \"Diff\", \"Cut-Off\", \"UID\"])\n",
    "\n",
    "uid_no = 1\n",
    "for vehicle in vehicles:\n",
    "    \n",
    "    testtrain = data[data[\"Vehicle\"] == vehicle]\n",
    "    testtrain[\"Diff\"] = testtrain[\"Timestamp\"].diff()\n",
    "    testtrain[\"Cut-Off\"] = testtrain[\"Diff\"] >= (45*60)\n",
    "    o = 0\n",
    "    #print(vehicle, \"-\", len(list(testtrain[testtrain[\"Cut-Off\"]].index)))\n",
    "    for i in list(testtrain[testtrain[\"Cut-Off\"]].index) + [testtrain.index.max()]:\n",
    "        #unique_train = generateUniqueId(uid_no)\n",
    "        unique_train = \"UID-\"+str(uid_no)\n",
    "        #print(unique_train)\n",
    "        #print(testtrain.loc[o:i-1])\n",
    "\n",
    "        try:\n",
    "            #ii = testtrain[\"Seconds\"].loc[o:i-1].idxmin()\n",
    "            ii = testtrain[\"Seconds\"].loc[o:i].idxmin()\n",
    "            values = list(testtrain.loc[ii]) + [unique_train]\n",
    "            #print(values)\n",
    "            \n",
    "            df2 = pd.DataFrame([values], columns=[\"Timestamp\", \"Line\", \"Vehicle\", \"Seconds\", \"Diff\", \"Cut-Off\", \"UID\"])\n",
    "            arrivals = arrivals.append(df2, ignore_index=True)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            #print(vehicle)\n",
    "        uid_no += 1\n",
    "        o = i\n",
    "arrivals = arrivals.sort_values(\"Timestamp\")[[\"Timestamp\", \"Line\", \"Vehicle\", \"Seconds\", \"UID\"]].reset_index(drop=True)\n",
    "\n",
    "print(arrivals[\"UID\"].nunique(), \"unique arrival IDs\")\n",
    "\n",
    "arrivals[\"Arrival Timestamp\"] = arrivals[\"Timestamp\"] + arrivals[\"Seconds\"]\n",
    "arrivals[\"Arrival Time\"] = [toReadableTime(x) for x in arrivals[\"Arrival Timestamp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load ATCS Arrival Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 444 ms, sys: 45.7 ms, total: 490 ms\n",
      "Wall time: 506 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "smcobject = open(\"190116SLS.smc\", \"r\")\n",
    "smclist = []\n",
    "\n",
    "\n",
    "for x in smcobject:\n",
    "    smclist.append(x)\n",
    "\n",
    "smcrecords = [x.replace(\"\\n\", \"\").strip() for x in smclist]\n",
    "\n",
    "del smclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505369 initial records\n",
      "8497 arrival records\n"
     ]
    }
   ],
   "source": [
    "day2read = \"2019-01-16\"\n",
    "readYear = day2read.split(\"-\")[0]\n",
    "readMonth= day2read.split(\"-\")[1]\n",
    "readDay= day2read.split(\"-\")[2]\n",
    "\n",
    "\n",
    "# remove records we don't want, so future operations are faster\n",
    "poplist = []\n",
    "couples = []\n",
    "\n",
    "print(len(smcrecords), \"initial records\")\n",
    "\n",
    "for i in range(len(smcrecords)):\n",
    "    rec = smcrecords[i].replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "    if \"Arrived\" in rec and \"Destination\" in rec and \"Platform\" in rec:\n",
    "        pass\n",
    "    elif \"Vehicle\" in rec and \"IDs\" in rec:\n",
    "        couples.append(smcrecords[i])\n",
    "        poplist.append(i)\n",
    "    else:    \n",
    "        poplist.append(i)\n",
    "\n",
    "for item in reversed(poplist):\n",
    "    smcrecords.pop(item)\n",
    "\n",
    "print(len(smcrecords), \"arrival records\")\n",
    "\n",
    "smcobject = open(\"190116SLS.smc\", \"r\")\n",
    "smclist = []\n",
    "\n",
    "\n",
    "for x in smcobject:\n",
    "    smclist.append(x)\n",
    "\n",
    "smcrecords = [x.replace(\"\\n\", \"\").strip() for x in smclist]\n",
    "\n",
    "del smclist\n",
    "\n",
    "coupleDict = {}\n",
    "\n",
    "for couple in couples:\n",
    "\n",
    "    info = couple.replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "    veh1 = consist_to_four_digit(info[6])\n",
    "    veh2 = consist_to_four_digit(info[7])\n",
    "\n",
    "    coupleDict[veh1] = veh2\n",
    "\n",
    "# remove records we don't want, so future operations are faster\n",
    "poplist = []\n",
    "couples = []\n",
    "\n",
    "for i in range(len(smcrecords)):\n",
    "    rec = smcrecords[i].replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "    if \"Arrived\" in rec and \"Destination\" in rec and \"Platform\" in rec:\n",
    "        pass\n",
    "    elif \"Vehicle\" in rec and \"IDs\" in rec:\n",
    "        couples.append(smcrecords[i])\n",
    "        poplist.append(i)\n",
    "    else:    \n",
    "        poplist.append(i)\n",
    "\n",
    "for item in reversed(poplist):\n",
    "    smcrecords.pop(item)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for record in smcrecords:\n",
    "    rec = [x.replace(\"{\",\"\").replace(\"}\",\"\") for x in record.split(\" \",2)]\n",
    "    dfs.append(pd.DataFrame([rec], columns=[\"TIME\", \"SRS_ID\", \"MSG\"]))\n",
    "\n",
    "smcdf = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "smcdf[\"CONSIST\"] = [re.sub(\"\\D\", \"\", x.lower().split()[x.lower().split().index('consist')+1]) if \"consist\" in x.lower().split() else '' for x in smcdf['MSG']]\n",
    "\n",
    "smcdf[\"FOUR_DIGIT_CONSIST\"] = [consist_to_four_digit(x) for x in smcdf['CONSIST']]\n",
    "smcdf[\"PLATFORM\"] = [x.split()[x.split().index(\"Platform\")+1] for x in smcdf[\"MSG\"]]\n",
    "\n",
    "smcdf[\"H\"] = [int(x.split(\":\")[0]) for x in smcdf[\"TIME\"]]\n",
    "dayChangeIdx = smcdf[smcdf[\"H\"].diff() < 0].index[0]\n",
    "smcdf.drop(\"H\", axis=1, inplace=True)\n",
    "\n",
    "smcdf[\"DAY\"] = np.NaN\n",
    "smcdf.loc[:(dayChangeIdx-1), \"DAY\"] = day2read\n",
    "smcdf.loc[dayChangeIdx:, \"DAY\"] = dayIncrement(readYear=readYear, readMonth=readMonth, readDay=readDay)\n",
    "\n",
    "smcdf[\"DATETIME\"] = smcdf[\"DAY\"] + \" \" + smcdf[\"TIME\"]\n",
    "\n",
    "\n",
    "#smcdf[\"DATETIME\"] = [pd.to_datetime(\"2019-01-16 \" +x) for x in smcdf[\"TIME\"]]\n",
    "smcdf[\"UNIX\"] = [(time.mktime(time.strptime(str(x).split(\".\")[0], \"%Y-%m-%d %H:%M:%S\"))) for x in smcdf[\"DATETIME\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc = smcdf\n",
    "coupleDict = {}\n",
    "\n",
    "for couple in couples:\n",
    "\n",
    "    info = couple.replace(\"{\", \"\").replace(\"}\",\"\").split()\n",
    "\n",
    "    veh1 = consist_to_four_digit(info[6])\n",
    "    veh2 = consist_to_four_digit(info[7])\n",
    "\n",
    "    coupleDict[veh1] = veh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 arrivals at VNR\n",
      "388 arrivals at VNR within timeframe\n"
     ]
    }
   ],
   "source": [
    "vnr = smc[smc[\"PLATFORM\"] == \"VNR\"].reset_index(drop=True)\n",
    "\n",
    "vnr = vnr[[\"DATETIME\",\"TIME\", \"UNIX\", \"FOUR_DIGIT_CONSIST\"]]\n",
    "vnr[\"SECOND_CONSIST\"] = [coupleDict[x] for x in vnr[\"FOUR_DIGIT_CONSIST\"]]\n",
    "print(len(vnr), \"arrivals at VNR\")\n",
    "\n",
    "t_min = data['Timestamp'].min() - 360\n",
    "t_max = data[\"Timestamp\"].max() + 360\n",
    "\n",
    "vnr_t = vnr[(vnr[\"UNIX\"] > t_min) & (vnr[\"UNIX\"] < t_max)]\n",
    "print(len(vnr_t), \"arrivals at VNR within timeframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load ATCS Sign Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signcodes = [\n",
    "    [\"8\",\"J\",\"OB\"],\n",
    "    [\"9\",\"J\",\"OB\"],\n",
    "    [\"10\",\"J\",\"OB\"],\n",
    "    [\"11\",\"J\",\"OB\"],\n",
    "    [\"12\",\"J\",\"OB\"],\n",
    "    [\"13\",\"J\",\"OB\"],\n",
    "    [\"14\",\"J\",\"IB\"],\n",
    "    [\"15\",\"J\",\"IB\"],\n",
    "    [\"30\",\"K\",\"OB\"],\n",
    "    [\"32\",\"K\",\"OB\"],\n",
    "    [\"33\",\"K\",\"IB\"],\n",
    "    [\"38\",\"K\",\"OB\"],\n",
    "    [\"55\", \"L\", \"OB\"],\n",
    "    [\"56\",\"L\",\"OB\"],\n",
    "    [\"57\",\"L\", \"OB\"],\n",
    "    [\"58\",\"L\",\"OB\"],\n",
    "    [\"60\", \"L\",\"OB\"],\n",
    "    [\"61\",\"L\",\"IB\"],\n",
    "    [\"62\",\"L\",\"IB\"],\n",
    "    [\"77\",\"M\",\"OB\"],\n",
    "    [\"80\",\"M\",\"OB\"],\n",
    "    [\"81\",\"M\",\"IB\"],\n",
    "    ['82',\"M\",\"IB\"],\n",
    "    [\"87\",\"M\",\"OB\"],\n",
    "    [\"91\",\"M\",\"OB\"],\n",
    "    [\"100\",\"N\",\"OB\"],\n",
    "    [\"103\",\"N\",\"OB\"],\n",
    "    [\"107\",\"N\",\"IB\"],\n",
    "    [\"108\",\"N\",\"OB\"],\n",
    "    [\"109\",\"N\",\"IB\"],\n",
    "    [\"115\",\"N\",\"IB\"],\n",
    "    [\"119\",\"N\",\"OB\"],\n",
    "    [\"124\",\"N\",\"OB\"],\n",
    "    [\"153\",\"T\",\"OB\"],\n",
    "    [\"161\",\"T\",\"IB\"],\n",
    "    [\"169\",\"T\",\"IB\"],\n",
    "    [\"175\",\"T\",\"IB\"],\n",
    "    [\"134\",\"S\",\"OB\"],\n",
    "    [\"135\",\"S\",\"OB\"],\n",
    "    [\"136\",\"S\",\"IB\"],\n",
    "    [\"215\",\"S\",\"IB\"],\n",
    "    [\"218\",\"S\",\"OB\"],\n",
    "    [\"137\",\"S\",\"IB\"],\n",
    "    [\"227\",\"X\",np.NaN]\n",
    "]\n",
    "\n",
    "signcodesDF = pd.DataFrame(data=signcodes, columns=[\"SIGN CODE\", \"LINE\", \"DIRECTION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 58.5 ms, total: 478 ms\n",
      "Wall time: 500 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "smcobject = open(\"190116SLS.smc\", \"r\")\n",
    "smclist = []\n",
    "\n",
    "\n",
    "for x in smcobject:\n",
    "    smclist.append(x)\n",
    "\n",
    "smcrecords = [x.replace(\"\\n\", \"\").strip() for x in smclist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 773 ms, total: 33.7 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "\n",
    "consist2signList = []\n",
    "\n",
    "for rec in smcrecords:\n",
    "    rec = rec.replace(\"{\",\"\").replace(\"}\",\"\")\n",
    "    rectime = rec.split(\" \")[0]\n",
    "    if \"Sign\" in rec:\n",
    "        try:\n",
    "            consist = rec.split()[rec.split().index(\"Consist\")+1]\n",
    "            if \"Sign\" in rec.split():\n",
    "                sign = rec.split()[rec.split().index(\"Sign\")+3]\n",
    "            elif \"Signs\" in rec.split():\n",
    "                sign = rec.split()[rec.split().index(\"Signs\")+1]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            consist2signList.append(pd.DataFrame(data=[[rectime, consist_to_four_digit(consist), sign]], columns=[\"TIME\",\"CONSIST\", \"SIGN CODE\"]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "#consist2sign = pd.concat(consist2signList, ignore_index=True).drop_duplicates(subset=[\"CONSIST\"], keep=\"last\").merge(signcodesDF, on=\"SIGN CODE\")\n",
    "test = pd.concat(consist2signList, ignore_index=True)\n",
    "\n",
    "day2read = \"2019-01-16\"\n",
    "readYear = \"2019\"\n",
    "readMonth = \"01\"\n",
    "readDay = \"16\"\n",
    "\n",
    "test[\"H\"] = [int(x.split(\":\")[0]) for x in test[\"TIME\"]]\n",
    "dayChangeIdx = test[test[\"H\"].diff() < 0].index[0]\n",
    "test.drop(\"H\", axis=1, inplace=True)\n",
    "\n",
    "test[\"DAY\"] = np.NaN\n",
    "test.loc[:(dayChangeIdx-1), \"DAY\"] = day2read\n",
    "test.loc[dayChangeIdx:, \"DAY\"] = dayIncrement(readYear=readYear, readMonth=readMonth, readDay=readDay)\n",
    "\n",
    "\n",
    "\n",
    "test[\"DATETIME\"] = test[\"DAY\"] + \" \" + test[\"TIME\"]\n",
    "\n",
    "test.drop([\"DAY\", \"TIME\"], axis=1, inplace=True)\n",
    "\n",
    "# remove sign codes that are not found in the reference\n",
    "test = test[test[\"SIGN CODE\"].isin(signcodesDF[\"SIGN CODE\"].unique())]\n",
    "\n",
    "# drop duplicate entries\n",
    "test = test.drop_duplicates(subset=[\"CONSIST\", \"DATETIME\", \"SIGN CODE\"])\n",
    "test[\"UNIX\"] = [(time.mktime(time.strptime(str(x).split(\".\")[0], \"%Y-%m-%d %H:%M:%S\"))) for x in test[\"DATETIME\"]]\n",
    "\n",
    "signs2consists = test.merge(signcodesDF, on=\"SIGN CODE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Match NextBus to ATCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchCodes = {\n",
    "    1 : \"MATCHED ON VEHICLE ID\",\n",
    "    2 : \"GHOST TRAIN; NO UN-MATCHED ARRIVALS\",\n",
    "    3 : \"ONE REMAINING MATCH; SAME LINE\",\n",
    "    4 : \"MATCHED TO OUT-OF-SERVICE TRAIN\",\n",
    "    5 : \"ONE REMAINING MATCH; DIFFERENT LINES\",\n",
    "    6 : \"UNMATCHED-UNKNOWN; MULTIPLE OUT-OF-SERVICE TRAINS\",\n",
    "    7 : \"MATCHED; ONE UN-MATCHED RECORD HAS SAME LINE\",\n",
    "    8 : \"UNMATCHED-UNKNOWN; MORE THAN 1 UNMATCHED ARRIVAL OF THAT LINE IN TIME-WINDOW\",\n",
    "    9 : \"GHOST TRAIN; NO ATCS RECORDS IN TIME-WINDOW\",\n",
    "    10 : \"UNMATCHED-UNKNOWN; MULTIPLE RECORDS OF OTHER LINES\"\n",
    "}\n",
    "\n",
    "matchDescriptions = {\n",
    "    \"MATCHED ON VEHICLE ID\" : \"The vehicle ID is present in both the NextBus and ATCS datasets within the given time window.\",\n",
    "    \"GHOST TRAIN; NO UN-MATCHED ARRIVALS\" : \"There are no un-matched arrivals in the ATCS dataset within the given time window\",\n",
    "    \"ONE REMAINING MATCH; SAME LINE\" : \"There is one remaining un-matched arrival in the ATCS dataset within the given time window, and it is the same line as the NextBus arrival.\",\n",
    "    \"MATCHED TO OUT-OF-SERVICE TRAIN\" : \"There is one remaining un-matched arrival in the ATCS dataset within the given time window, and it shown as an out-of-service train.\",\n",
    "    \"ONE REMAINING MATCH; DIFFERENT LINES\" : \"There is one remaining un-matched arrival in the ATCS dataset within the given time window, and it is a different line than the NextBus arrival.\",\n",
    "    \"UNMATCHED-UNKNOWN; MULTIPLE OUT-OF-SERVICE TRAINS\" : \"There are multiple remaining un-matched arrivals in the ATCS dataset within the given time window, and they are shown as out-of-service trains\",\n",
    "    \"MATCHED; ONE UN-MATCHED RECORD HAS SAME LINE\" : \"There is one remaining un-matched arrival in the ATCS dataset within the given time window, and it is the same line as the NextBus arrival.\",\n",
    "    \"UNMATCHED-UNKNOWN; MORE THAN 1 UNMATCHED ARRIVAL OF THAT LINE IN TIME-WINDOW\" : \"There are multiple remaining un-matched arrivals in the ATCS dataset within the given time window, and more than one is the same line as the NextBus arrival\",\n",
    "    \"GHOST TRAIN; NO ATCS RECORDS IN TIME-WINDOW\" : \"There are no ATCS arrivals within the given time window.\",\n",
    "    \"UNMATCHED-UNKNOWN; MULTIPLE RECORDS OF OTHER LINES\" : \"There are multiple remaining un-matched arrivals in the ATCS dataset within the given time window, and they are different lines than the NextBus arrival.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mapsense-simon/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "unmatchedATCSarrivals.drop(0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1428 GHOST TRAIN -- no arrivals in time window.\n",
      "1532 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1410 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1420 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1488 GHOST TRAIN -- no arrivals in time window.\n",
      "1532 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1428 GHOST TRAIN -- no arrivals in time window.\n",
      "1507 GHOST TRAIN -- no arrivals in time window.\n",
      "1529 MATCHED -- Matched via removal & line.\n",
      "2026 One remaining match; mismatched lines: KT vs. M\n",
      "1469 GHOST TRAIN -- no arrivals in time window.\n",
      "1487 One remaining match; mismatched lines: N vs. M\n",
      "1411 One remaining match; mismatched lines: L vs. M\n",
      "2030 One remaining match; mismatched lines: N vs. L\n",
      "1428 GHOST TRAIN -- no arrivals in time window.\n",
      "2013 One remaining match; mismatched lines: M vs. N\n",
      "2020 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1417 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1403 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "2011 GHOST TRAIN -- no arrivals in time window.\n",
      "2009 MATCHED -- Only eligible match is an out of service train\n",
      "2041 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "2014 One remaining match; mismatched lines: J vs. N\n",
      "2046 GHOST TRAIN -- no arrivals in time window.\n",
      "1428 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1500 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "1542 GHOST TRAIN -- no remaining, un-matched arrival in time window.\n",
      "CPU times: user 7.27 s, sys: 165 ms, total: 7.43 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matchTimeDif = []\n",
    "\n",
    "unmatchedNBarrivals = arrivals[arrivals[\"Seconds\"] <= 60].copy(deep=True)\n",
    "unmatchedATCSarrivals = vnr_t.copy(deep=True)\n",
    "\n",
    "#matchedNBidx = []\n",
    "matchedATCSidx = []\n",
    "\n",
    "arrivalMatchingCols = [\"NextBus Vehicle ID\", \"NextBus Arrival Time\", \"Match Code\", \"Match Code Description\"]\n",
    "arrivalMatching = pd.DataFrame(columns=arrivalMatchingCols)\n",
    "\n",
    "\n",
    "numArrivals = len(arrivals[arrivals[\"Seconds\"] <= 60].index)\n",
    "matches = 0\n",
    "confirmedGhosts = 0\n",
    "matchedViaRemovalLine = 0\n",
    "\n",
    "timeRadius = 180\n",
    "\n",
    "for i in arrivals[arrivals[\"Seconds\"] <= 60].index:\n",
    "    # generate time window\n",
    "    arrivalTime = arrivals.loc[i, \"Timestamp\"]\n",
    "    arrivalVehID = arrivals.loc[i, \"Vehicle\"]\n",
    "    arrivalLine = arrivals.loc[i, \"Line\"]\n",
    "    t_max = arrivalTime + timeRadius\n",
    "    t_min = arrivalTime - timeRadius\n",
    "    \n",
    "    # generate DFs of only arrivals within the time window\n",
    "    searchDFarrivals = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"UNIX\"] < t_max) & (unmatchedATCSarrivals[\"UNIX\"] > t_min)]\n",
    "    arrivalDFarrivals = arrivals[(arrivals[\"Timestamp\"] < t_max) & (arrivals[\"Timestamp\"] > t_min)]\n",
    "    \n",
    "    # ASSIGN LINE INFORMATION TO ATCS LOGS\n",
    "    if len(searchDFarrivals) > 0:\n",
    "        \n",
    "        dfs = []\n",
    "\n",
    "        for m in searchDFarrivals.index:\n",
    "            car1 = searchDFarrivals.loc[m, \"FOUR_DIGIT_CONSIST\"]\n",
    "            unix = searchDFarrivals.loc[m, \"UNIX\"]\n",
    "\n",
    "            #print(car1, car2)\n",
    "\n",
    "            tempDF = signs2consists[(signs2consists[\"CONSIST\"].isin([car1])) & (signs2consists[\"UNIX\"] <= unix) & (signs2consists[\"UNIX\"] >= (unix - (60*60)))].sort_values(\"UNIX\")\n",
    "\n",
    "            if len(tempDF) == 0:\n",
    "                line = \"X\"\n",
    "            else:\n",
    "                line = tempDF.loc[tempDF[\"UNIX\"].idxmax(), \"LINE\"]\n",
    "            dfs.append(pd.DataFrame([[car1, line]], columns=[\"FOUR_DIGIT_CONSIST\", \"LINE\"]))\n",
    "\n",
    "        try:\n",
    "            lineAssignments = pd.concat(dfs, ignore_index=True)\n",
    "        except ValueError:\n",
    "            print(len(searchDFarrivals))\n",
    "\n",
    "        searchDFarrivals = searchDFarrivals.merge(lineAssignments, on=\"FOUR_DIGIT_CONSIST\")\n",
    "\n",
    "        # OK, now that the arrivals dataset (NB) is loaded and subset, and the search dataset (ATCS) is both subset and has lines assigned\n",
    "        # we can proceed\n",
    "        \n",
    "        \n",
    "        \n",
    "        if arrivalVehID in list(searchDFarrivals[\"FOUR_DIGIT_CONSIST\"]):\n",
    "            \n",
    "            # OPTION 1 -- MATCHED ON VEHICLE ID \n",
    "            # the vehicle ID is present in both datasets, thereby allowing us to make the match.\n",
    "            # This NextBus arrival is therefore considered to be MATCHED.\n",
    "            matchCodeID = 1\n",
    "            matches += 1\n",
    "            #matchedNBidx.append(i)\n",
    "            unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "            \n",
    "            sdf_idx = list(searchDFarrivals[\"FOUR_DIGIT_CONSIST\"]).index(arrivalVehID)\n",
    "            datetime_value = searchDFarrivals[\"DATETIME\"][sdf_idx]\n",
    "            atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value) & (unmatchedATCSarrivals[\"FOUR_DIGIT_CONSIST\"] == arrivalVehID)].index[0]\n",
    "            \n",
    "            matchTimeDif.append(arrivalTime-unmatchedATCSarrivals.loc[atcs_idx, \"UNIX\"])\n",
    "            \n",
    "            unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "            \n",
    "            \n",
    "        elif arrivalVehID in list(searchDFarrivals[\"SECOND_CONSIST\"]):\n",
    "            \n",
    "            # OPTION 1 -- MATCHED ON VEHICLE ID \n",
    "            # the vehicle ID is present in both datasets, thereby allowing us to make the match.\n",
    "            # This NextBus arrival is therefore considered to be MATCHED.\n",
    "            matchCodeID = 1\n",
    "            matches += 1\n",
    "            #matchedNBidx.append(i)\n",
    "            unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "            \n",
    "            sdf_idx = list(searchDFarrivals[\"SECOND_CONSIST\"]).index(arrivalVehID)\n",
    "            datetime_value = searchDFarrivals[\"DATETIME\"][sdf_idx]\n",
    "            atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value) & (unmatchedATCSarrivals[\"SECOND_CONSIST\"] == arrivalVehID)].index[0]\n",
    "            \n",
    "            matchTimeDif.append(arrivalTime -unmatchedATCSarrivals.loc[atcs_idx, \"UNIX\"])\n",
    "            \n",
    "            unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "            \n",
    "            \n",
    "        # If the vehicle ID is not found in the search dataset, we can take several actions.    \n",
    "        else:\n",
    "            \n",
    "            # create an array of vehicle IDs that are present in both the substs of the arrivals dataset and the search dataset.\n",
    "            # these records can be considered to be MATCHED, thereby removing them from our consideration\n",
    "            otherMatches = []\n",
    "            for veh in arrivalDFarrivals[\"Vehicle\"].unique():\n",
    "\n",
    "                if veh in list(searchDFarrivals[\"FOUR_DIGIT_CONSIST\"]):\n",
    "                    otherMatches.append(veh)\n",
    "                elif veh in list(searchDFarrivals[\"SECOND_CONSIST\"]):\n",
    "                    otherMatches.append(veh)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            # the resultant DF is all of the arrivals within the subset search dataset for which there are no matching vehicle\n",
    "            # ID matches in the subset arrivals dataset\n",
    "            \n",
    "            searchArrivals = searchDFarrivals[searchDFarrivals[\"FOUR_DIGIT_CONSIST\"].isin(otherMatches) == False]\n",
    "            \n",
    "            \n",
    "            if len(searchArrivals) == 0:\n",
    "                \n",
    "                # OPTION 2 -- GHOST TRAIN; NO UN-MATCHED ARRIVALS\n",
    "                # there are no un-matched arrivals in the subset search dataset\n",
    "                # This NextBus arrival is therefore considered to be a GHOST TRAIN.\n",
    "                matchCodeID = 2\n",
    "                confirmedGhosts += 1\n",
    "                print(arrivalVehID, \"GHOST TRAIN -- no remaining, un-matched arrival in time window.\")\n",
    "            \n",
    "            # if there is only one train in the remaining, un-matched subset of the search dataset, a number of outcomes can occur \n",
    "            elif len(searchArrivals) == 1:\n",
    "                \n",
    "                \n",
    "                if arrivalLine == searchArrivals.iloc[0][\"LINE\"]:\n",
    "                    \n",
    "                    # OPTION 3 -- ONE REMAINING MATCH; SAME LINES\n",
    "                    # the remaining, un-matched train in the subset search dataset is of the same line as the NextBus\n",
    "                    # arrival being investigated, thereby allowing us to assert that the NextBus arrival matches this lone remaining\n",
    "                    # un-matched ATCS arrival This NextBus arrival is therefore considered to be MATCHED.\n",
    "                    \n",
    "                    print(arrivalVehID, \"MATCHED -- Matched via removal & line.\")\n",
    "                    matchCodeID = 3\n",
    "                    matches += 1\n",
    "                    matchedViaRemovalLine += 1\n",
    "                    #matchedNBidx.append(i)\n",
    "                    unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "                    \n",
    "                    sdf_idx = 0\n",
    "                    datetime_value = searchArrivals[\"DATETIME\"][sdf_idx]\n",
    "                    atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value)].index[0]\n",
    "                    unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "                \n",
    "                elif searchArrivals.iloc[0][\"LINE\"] == \"X\":\n",
    "                    \n",
    "                    # OPTION 4 -- MATCHED TO OUT-OF-SERVICE TRAIN\n",
    "                    # the remaining, un-matched train in the subset search dataset is of line \"X\", which indicates \n",
    "                    # an out of service train. Because this is the only matching train within the time window and it does not contain \n",
    "                    # any information that would conflict with the information about the NextBus arrival, we are able to assert that \n",
    "                    # the NextBus arrival matches this train that the train control system considers to be out-of-service.\n",
    "                    \n",
    "                    matchCodeID = 4\n",
    "                    print(arrivalVehID, \"MATCHED -- Only eligible match is an out of service train\")\n",
    "                    #matchedNBidx.append(i)\n",
    "                    unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "                    \n",
    "                    sdf_idx = 0\n",
    "                    datetime_value = searchArrivals[\"DATETIME\"][sdf_idx]\n",
    "                    atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value)].index[0]\n",
    "                    unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    # OPTION 5 -- ONE REMAINING MATCH; DIFFERENT LINES \n",
    "                    # the remaining, un-matched train in the subset search dataset is of a different line than the line of \n",
    "                    # the NextBus arrival being investigated.\n",
    "                    \n",
    "                    matchCodeID = 5\n",
    "                    print(arrivalVehID, \"One remaining match; mismatched lines:\", arrivalLine, \"vs.\", searchArrivals.iloc[0][\"LINE\"])\n",
    "    \n",
    "            \n",
    "            # if there is more than one remaining, un-matched arrival record in the subset search dataset, there are a number of\n",
    "            # steps we can take to try to match those search dataset records with the NextBus record we're investigating\n",
    "            \n",
    "            elif len(searchArrivals) > 1:\n",
    "                try:\n",
    "                    # count the number of times the line of the NextBus arrival appears in the un-matched subset search DataFrame\n",
    "                    obs = dict(searchDFarrivals['LINE'].value_counts())[arrivalLine]\n",
    "                    \n",
    "                except KeyError:\n",
    "                    # if the line of the NextBus arrival being investigated is not present in the subset search arrival records\n",
    "                    # we first try to determine if there is a train considered to be out-of-service present\n",
    "                    try:\n",
    "                        if dict(searchDFarrivals['LINE'].value_counts())[\"X\"] == 1:\n",
    "                            \n",
    "                            # OPTION 4 -- MATCHED TO AN OUT-OF-SERVICE TRAIN\n",
    "                            # if there are no arrival records from the un-matched, subset search dataset that match the line of the \n",
    "                            # NextBus arrival being investigated, but there is one out-of-service train in that subset, we can match\n",
    "                            # that out-of-service train to the NextBus arrival. This NextBus arrival is therefore considered to be MATCHED.\n",
    "                            \n",
    "                            matchCodeID = 4\n",
    "                            obs = 0\n",
    "                            print(arrivalVehID, \"MATCHED -- MATCHED TO A OUT-OF-SERVICE TRAIN\")\n",
    "                            #matchedNBidx.append(i)\n",
    "                            unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "                            \n",
    "                            sdf_idx = list(searchDFarrivals[\"SECOND_CONSIST\"]).index(arrivalVehID)\n",
    "                            datetime_value = searchDFarrivals[\"DATETIME\"][sdf_idx]\n",
    "                            atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value) & (unmatchedATCSarrivals[\"SECOND_CONSIST\"] == arrivalVehID)].index[0]\n",
    "                            unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "                            \n",
    "                        elif dict(searchDFarrivals['LINE'].value_counts())[\"X\"] > 1:\n",
    "                            \n",
    "                            # OPTION 6 -- UNMATCHED-UNKNOWN; MULTIPLE OUT-OF-SERVICE TRAINS\n",
    "                            # if there are no arrival records from the un-matched, subset search dataset that match the line of the \n",
    "                            # NextBus arrival being investigated, but there is more than one out-of-service trains in that subset, we are\n",
    "                            # unable to make a match across datasets. This NextBus arrival is therefore considered to be UNMATCHED-UNKNOWN.\n",
    "                            \n",
    "                            matchCodeID = 6\n",
    "                            obs = 0\n",
    "                            print(arrivalVehID, \"UNMATCHED-UNKNOWN -- multiple out-of-service trains\")\n",
    "                            \n",
    "                        else:\n",
    "                            \n",
    "                            # this scenario is impossible; if there are 0 records with line \"X\", the above IF statement will throw\n",
    "                            # a KeyError\n",
    "                            pass\n",
    "                        \n",
    "                    except KeyError:\n",
    "                        obs = 0\n",
    "                        \n",
    "                        # OPTION 10 -- UNMATCHED-UNKNOWN; MULTIPLE RECORDS OF OTHER LINES\n",
    "                        # of the remaining, un-matched records, there are multiple records belonging to other lines\n",
    "                        # than the line indidicated in the NextBus data\n",
    "                        \n",
    "                        matchCodeID = 10\n",
    "                        print(arrivalVehID, \"UNMATCHED-UNKNOWN - No records of NextBus line or out-of-service trains. Multiple records of other lines.\")\n",
    "                \n",
    "                if obs == 1:\n",
    "                    \n",
    "                    # OPTION 7 -- MATCHED; ONE UN-MATCHED RECORD HAS SAME LINE\n",
    "                    # of the remaining, un-matched records from the subset search dataset, only one belongs to the same\n",
    "                    # line as the NextBus arrival being investigated, which allows us to match the NextBus arrival to that search \n",
    "                    # record. This NextBus arrival is therefore considered to be MATCHED.\n",
    "                    \n",
    "                    matchCodeID = 7\n",
    "                    print(arrivalVehID, \"MATCHED --  via removal & line (only one match with predicted line.)\")\n",
    "                    matches += 1\n",
    "                    #matchedNBidx.append(i)\n",
    "                    unmatchedNBarrivals.drop(i, axis=0, inplace=True)\n",
    "                    \n",
    "                    sdf_idx = list(searchDFarrivals[\"SECOND_CONSIST\"]).index(arrivalVehID)\n",
    "                    datetime_value = searchDFarrivals[\"DATETIME\"][sdf_idx]\n",
    "                    atcs_idx = unmatchedATCSarrivals[(unmatchedATCSarrivals[\"DATETIME\"] == datetime_value) & (unmatchedATCSarrivals[\"SECOND_CONSIST\"] == arrivalVehID)].index[0]\n",
    "                    unmatchedATCSarrivals.drop(atcs_idx, axis=0, inplace=True)\n",
    "                    \n",
    "                elif obs > 1:\n",
    "                    \n",
    "                    # OPTION 8 -- UNMATCHED-UNKNOWN; MORE THAN 1 UNMATCHED ARRIVAL OF THAT LINE IN TIME-WINDOW\n",
    "                    # if there is more than one un-matched arrival record from the subset search dataset that belongs to\n",
    "                    # the same line as the NextBus arrival being investigated, we are unable to to match the NextBus arrival to an\n",
    "                    # arrival in the subset search dataset. This NextBus arrival is therefore considered to be UNMATCHED-UNKNOWN.\n",
    "                    \n",
    "                    matchCodeID = 8\n",
    "                    print(arrivalVehID, \"UNMATCHED-UNKNOWN -- More than 1 unmatched arrival of that line in the time window.\")\n",
    "                \n",
    "                else:\n",
    "                    # OPTION 6 or OPTION 7 occurred and has been already noted.\n",
    "                    pass\n",
    "            else:\n",
    "                # we can't have a DataFrame searchArrivals of negative length, so this scenario is impossible\n",
    "                pass\n",
    "    else:\n",
    "        ## OPTION 9 -- GHOST TRAIN; NO RECORDS IN TIME-WINDOW \n",
    "        # no arrival records were present in the subset search dataset. \n",
    "        # This NextBus arrival is therefore considered to be a GHOST TRAIN.\n",
    "        confirmedGhosts += 1\n",
    "        matchCodeID = 9\n",
    "        print(arrivalVehID, \"GHOST TRAIN -- no arrivals in time window.\")\n",
    "        \n",
    "    matchresults = [arrivalVehID, toReadableTime(arrivalTime), matchCodeID, matchCodes[matchCodeID]]\n",
    "    arrivalMatching = arrivalMatching.append(pd.DataFrame([matchresults], columns=arrivalMatchingCols), ignore_index=True)  \n",
    "    \n",
    "#unmatchedNBarrivals.drop(matchedNBidx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Examining the Differences Between NextBus and ATCS Arrivals\n",
    "\n",
    "I collected the differences between the NextBus predicted arrivals and the ATCS observed arrivals to try to determine if there was any behavior that could be used to better tune the rest of the matcher. I examined time differences only between records that I was able to match based on vehicle ID number. __I found that the NextBus prediction is for an earlier time than the ATCS observation in every event.__\n",
    "\n",
    "Below, the differences in the time are shown. The values were generated by subtracting the timestamp of the ATCS obvservation from the timestamp of the NextBus Predicted arrival. Thus, a negative value indicates that the timestamp of the ATCS observation is greater than the timestamp of the NextBusPredicted arrival, which means the ATCS observation occurred _after_ the NextBus Predicted arrival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(matchTimeDif, bins=20)\n",
    "\n",
    "plt.xlabel(\"NextBus Arrival - ATCS Arrival (seconds)\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.title(\"Comparison of Arrival Times:\\nNextBus vs. ATCS\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    345.000000\n",
       "mean     -39.966917\n",
       "std       33.025794\n",
       "min     -179.893535\n",
       "25%      -44.629683\n",
       "50%      -26.832204\n",
       "75%      -20.160515\n",
       "max       -1.260194\n",
       "Name: Seconds, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NextBus Arrival Timestamp - ATCS observed Timestamp\n",
    "\n",
    "# ATCS was always after the NextBus value\n",
    "\n",
    "# the median number of seconds after a NB value the ATCS arrival would occur is 26.8 seconds.\n",
    "\n",
    "\n",
    "pd.Series(matchTimeDif, name=\"Seconds\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Match ATCS to NextBus\n",
    "\n",
    "Taking the remaining vehicles that were not matched in the first step, NextBus to ATCS, run the matcher backwards and try to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through remaining unmatched ATCS observations\n",
    "for j in unmatchedATCSarrivals.index:\n",
    "    \n",
    "    # attributes of the unmatched ATCS observation\n",
    "    arrivalUnix = unmatchedATCSarrivals.loc[j, \"UNIX\"]\n",
    "    four_digit_consist = unmatchedATCSarrivals.loc[j, \"FOUR_DIGIT_CONSIST\"]\n",
    "    second_consist = unmatchedATCSarrivals.loc[j, \"SECOND_CONSIST\"]\n",
    "    \n",
    "    # assign line information to the unmatched ATCS observation\n",
    "    subsetLines = signs2consists[(signs2consists[\"CONSIST\"].isin([four_digit_consist, second_consist])) & (signs2consists[\"UNIX\"] <= arrivalUnix) & (signs2consists[\"UNIX\"] >= (arrivalUnix - (60*60)))].sort_values(\"UNIX\")\n",
    "    ATCSline = subsetLines.loc[subsetLines[\"UNIX\"].idxmax(), \"LINE\"]\n",
    "    \n",
    "    if ATCSline == \"T\":\n",
    "        ATCSline = \"KT\"\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # create a DataFrame of unmatched NextBus arrivals within the time window surrounding the the ATCS arrival\n",
    "    potentialBackMatches = unmatchedNBarrivals[(unmatchedNBarrivals[\"Arrival Timestamp\"] < (arrivalUnix + timeRadius)) & (unmatchedNBarrivals[\"Arrival Timestamp\"] > (arrivalUnix - timeRadius))].copy(deep=True)\n",
    "    potentialBackMatches[\"ArrivalTimeDif\"] = [x - arrivalUnix for x in potentialBackMatches[\"Arrival Timestamp\"]]\n",
    "    potentialBackMatches[\"PercentileTimeDif\"] = [stats.percentileofscore(matchTimeDif, x) for x in potentialBackMatches[\"ArrivalTimeDif\"]]\n",
    "    \n",
    "    # if there is a potential match, iterate through\n",
    "    if len(potentialBackMatches) != 0:\n",
    "        for l in potentialBackMatches.index:\n",
    "            \n",
    "            # check if there is a line match\n",
    "            if ATCSline == potentialBackMatches.loc[l, \"Line\"]:\n",
    "                \n",
    "                matchCodeID = 7\n",
    "                matchresults = [potentialBackMatches.loc[l, \"Vehicle\"], toReadableTime(potentialBackMatches.loc[l, \"Timestamp\"]), matchCodeID, matchCodes[matchCodeID]]\n",
    "                arrivalMatching = arrivalMatching.append(pd.DataFrame([matchresults], columns=arrivalMatchingCols), ignore_index=True)  \n",
    "\n",
    "                unmatchedNBarrivals.drop(l, axis=0, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        pass\n",
    "                \n",
    "        \n",
    "arrivalMatching.drop_duplicates(subset=[\"NextBus Vehicle ID\", \"NextBus Arrival Time\"], keep=\"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptiveStats = pd.DataFrame(arrivalMatching[\"Match Code Description\"].value_counts())\n",
    "\n",
    "\n",
    "reportPath = \"REPORT-{}.txt\".format(day2read)\n",
    "\n",
    "f = open(reportPath, \"w\")\n",
    "\n",
    "f.write(\"NextBus/ATCS Matching Rerport for \" + day2read + \"\\n\")\n",
    "f.write(\"For support, contact Transit Technology Group\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.write(\"** Daily Overview for \" + day2read + \" **\\n\")\n",
    "f.write(\"\\n\\n\")\n",
    "\n",
    "for i in descriptiveStats.index:\n",
    "    \n",
    "    count = int(descriptiveStats.loc[i, \"Match Code Description\"])\n",
    "    pct = round(count/len(arrivalMatching),3) * 100\n",
    "    \n",
    "    beginning = i\n",
    "    end = \"{} of {} arrivals ({}%)\".format(count, len(arrivalMatching), pct)\n",
    "    \n",
    "    summary = beginning + \" \" + ''.join([\"-\" for x in np.zeros(108-(len(beginning) + len(end)))]) + \" \" + end + \"\\n\"\n",
    "    \n",
    "    f.write(summary)\n",
    "\n",
    "f.write(\"\\n\\n\")\n",
    "f.write(\"Vehicle IDs listed below are considered to be un-matched. They are sorted by matching failure.\\n\\n\")\n",
    "f.write(\"Arrivals are shown in the following format:\\n<VEHICLE ID> -- <NEXTBUS ARRIVAL PREDICTION>\\n\\n\")\n",
    "\n",
    "for i in list(descriptiveStats[descriptiveStats.index.isin([matchCodes[x] for x in[2,5,6,8,9,10]])].index):\n",
    "    f.write(\"* \" + i + \" * \\n\")\n",
    "    f.write(matchDescriptions[i] + \"\\n\\n\")\n",
    "    for row in arrivalMatching[arrivalMatching[\"Match Code Description\"] == i].iterrows():\n",
    "        index, data = row\n",
    "\n",
    "        vehID = data[0]\n",
    "        arrivalTimestamp = data[1]\n",
    "        f.write(str(vehID) + \" -- \" + str(arrivalTimestamp) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arrivalMatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Code Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MATCHED ON VEHICLE ID</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHOST TRAIN; NO UN-MATCHED ARRIVALS</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHOST TRAIN; NO ATCS RECORDS IN TIME-WINDOW</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONE REMAINING MATCH; DIFFERENT LINES</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATCHED TO OUT-OF-SERVICE TRAIN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONE REMAINING MATCH; SAME LINE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATCHED; ONE UN-MATCHED RECORD HAS SAME LINE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Match Code Description\n",
       "MATCHED ON VEHICLE ID                                            345\n",
       "GHOST TRAIN; NO UN-MATCHED ARRIVALS                               11\n",
       "GHOST TRAIN; NO ATCS RECORDS IN TIME-WINDOW                        8\n",
       "ONE REMAINING MATCH; DIFFERENT LINES                               6\n",
       "MATCHED TO OUT-OF-SERVICE TRAIN                                    1\n",
       "ONE REMAINING MATCH; SAME LINE                                     1\n",
       "MATCHED; ONE UN-MATCHED RECORD HAS SAME LINE                       1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptiveStats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
